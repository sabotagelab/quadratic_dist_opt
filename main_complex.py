import argparse
import matplotlib.pyplot as plt
import mpl_toolkits.mplot3d.art3d as art3d
import numpy as np

from objective import Objective
from generate_trajectories import Quadrocopter
from generate_trajectories import generate_agent_states, generate_init_traj_quad
import sys


EPS = 1e-2

if __name__ == "__main__":
    np.random.seed(42)

    parser = argparse.ArgumentParser(description='Optimization')
    parser.add_argument('--N', type=int, default=3)
    parser.add_argument('--H', type=int, default=5)
    parser.add_argument('--alpha', type=float, default=0.001)
    parser.add_argument('--beta', type=float, default=1)
    parser.add_argument('--gamma', type=float, default=.1)
    parser.add_argument('--kappa', type=float, default=0.5)
    parser.add_argument('--eps_bounds', type=float, default=25)
    
    parser.add_argument('--ro', type=float, default=.5)
    parser.add_argument('--co', type=float, default=3)
    parser.add_argument('--rg', type=float, default=5)
    parser.add_argument('--cg', type=float, default=5)
    parser.add_argument('--Ubox', type=float, default=100)  # NEED A LARGER UBOX THAN IN THE SIMPLE EXAMPLE
    parser.add_argument('--iter', type=int, default=1000)

    parser.add_argument('--Tf', type=int, default=1)

    args = parser.parse_args()
    print(args)

    notion = 2
    N = args.N  # number of agents
    alpha = args.alpha   # parameter for fairness constraint
    beta = args.beta    # parameter for weighting of obstacle avoidance constraint
    gamma = args.gamma   # parameter for smoothmin in calculating obstacle avoidance constraint
    kappa = args.kappa   # parameter for weighting change in epsilon for local problem
    eps_bounds = args.eps_bounds  # bounds for eps in an iteration

    ro = args.ro  # radius of circle
    co = np.array([args.co, args.co, args.co])  # center of circle
    rg = args.rg
    cg = np.array([args.cg, args.cg, 0])
    obstacles = {'center': co, 'radius': ro}
    target = {'center': cg, 'radius': rg}
    Ubox = args.Ubox  # box constraint

    H = args.H

    Tf = args.Tf
    
    # SET INITIAL POSITIONS AND STATES
    # init_pos = [np.array([-3, 3, 0]), np.array([-3, -3, 0]), np.array([3, -3, 0])]
    # x = -5
    # y = -5
    x = np.random.uniform(low=-15, high=0, size=1)[0]
    y = np.random.uniform(low=-15, high=15, size=1)[0]

    init_pos = []
    init_states = []
    for i in range(N):
        # x = np.random.uniform(low=-15, high=15, size=1)[0]
        # y = np.random.uniform(low=-15, high=15, size=1)[0]
        init_pos.append(np.array([x+(i), y, 0]))
        # init_pos.append(np.array([x, y, 0]))
        s = [init_pos[i]]
        s.append(np.array([0, 0, 0]))  # velo
        init_states.append(np.array(s).flatten())

    # GENERATE INITIAL "CONTROL INPUTS" AND TRAJECTORIES
    init_u = []
    init_traj = []
    for i in range(N):
        traj_pos, traj_accel = generate_init_traj_quad(init_pos[i], cg, H, Tf=Tf)
        init_u.append(traj_accel)
        init_traj.append(traj_pos)
    init_u = np.array(init_u)

    # PLOT INITIAL TRAJECTORIES AS GENERATED BY ANDREAS CODE
    # fig = plt.figure()
    # ax = fig.add_subplot(projection='3d')
    # for i in range(N):
    #     # print("generated trajectory {}".format(i))
    #     # print(init_traj[i])
    #     ax.scatter(init_traj[i][:,0], init_traj[i][:,1], init_traj[i][:,2], label=i)
    # plt.show()

    # PLOT INITIAL TRAJECTORIES FROM "CONTROL INPUTS"
    init_trajectories = []
    fig = plt.figure()
    ax = fig.add_subplot(projection='3d')
    times = np.linspace(0, Tf, H)
    for i in range(N):
        states, traj = generate_agent_states(init_u[i], init_states[i], init_pos[i], model=Quadrocopter, dt=Tf/H*1.5)
        ax.scatter(traj[:,0], traj[:,1], traj[:,2], label=i)
        init_trajectories.append(traj)
        # print(traj)
    obs = plt.Circle((co[0], co[1]), ro, fill=True, alpha=0.2, color='red')
    ax.add_patch(obs)
    art3d.pathpatch_2d_to_3d(obs, z=co[2])
    goal = plt.Circle((cg[0], cg[1]), rg, fill=True, alpha=0.2, color='green')
    ax.add_patch(goal)
    art3d.pathpatch_2d_to_3d(goal, z=cg[2])
    plt.savefig('plots/quad/agent_init_trajectories_N{}.png'.format(N))
    plt.clf()

    # GENERATE SOLO ENERGIES
    print('Generating Solo Energies')
    system_model = Quadrocopter
    control_input_size = 3
    system_model_config = (Quadrocopter, control_input_size)
    solo_energies = []
    for i in range(N):
        n = 1*H*control_input_size
        Q = np.eye(n)
        obj = Objective(1, H, system_model_config, [init_states[i]], [init_pos[i]], obstacles, target, Q, alpha, beta, gamma, kappa, eps_bounds, Ubox, dt=Tf/H*1.5, notion=notion)
        final_obj, final_u = obj.solve_central(init_u[i], steps=args.iter)
        init_solo_energy = obj.quad(final_u.flatten())
        solo_energies.append(init_solo_energy)

    # INIT SOLVER
    print('Solving Central Problem')
    n = N*H*control_input_size
    # Q = np.eye(n)
    Q = np.random.randn(n, n)   # variable for quadratic objective
    Q = Q.T @ Q
    obj = Objective(N, H, system_model_config, init_states, init_pos, obstacles, target, Q, alpha, beta, gamma, kappa, eps_bounds, Ubox, dt=Tf/H*1.5, notion=notion)
    print(obj.reach_constraint(init_u.flatten()))
    obj.solo_energies = solo_energies

    # METRICS FOR INITIAL TRAJECTORY
    init_obj = obj.quad(init_u.flatten())
    print('Initial Obj {}'.format(init_obj))
    print('Initial Total Energy Cost (Lower is better)')
    init_energy = obj.quad(init_u.flatten())
    print(init_energy)
    print('Initial Fairness (Close to 0 is better)')
    init_fairness = obj.fairness(init_u.flatten())
    print(init_fairness)
    print('Initial Obstacle Avoidance Cost (More Negative Is Better)')
    init_obstacle = obj.obstacle(init_u.flatten())
    print(init_obstacle)
    print('Initial Collision Avoidance Cost (More Negative Is Better)')
    init_collision = obj.avoid_constraint(init_u.flatten())
    print(init_collision)

    # SOLVE USING CENTRAL
    # final_obj, final_u = obj.solve_central(init_u, steps=args.iter)
    # if len(final_u) != 0:
    #     # METRICS FOR FINAL TRAJECTORY AFTER SOLVING CENTRAL PROBLEM
    #     central_sol_obj = final_obj
    #     print('Central Final Obj {}'.format(central_sol_obj))
    #     final_u = final_u.reshape(N, H, control_input_size)    
    #     print('Central Final Total Energy Cost (Lower is better)')
    #     central_sol_energy = obj.quad(final_u.flatten())
    #     print(central_sol_energy)
    #     print('Central Final Fairness (Close to 0 is better)')
    #     central_sol_fairness = obj.fairness(final_u.flatten())
    #     print(central_sol_fairness)
    #     print('Central Final Obstacle Avoidance Cost (More Negative Is Better)')
    #     central_sol_obstacle = obj.obstacle(final_u.flatten())
    #     print(central_sol_obstacle)
    #     print('Central Final Collision Avoidance Cost (More Negative Is Better)')
    #     central_sol_collision = obj.avoid_constraint(final_u.flatten())
    #     print(central_sol_collision)

    #     # PLOT FINAL TRAEJECTORIES FROM CONTROL INPUTS
    #     final_trajectories = []
    #     fig = plt.figure()
    #     ax = fig.add_subplot(projection='3d')
    #     times = np.linspace(0, Tf, H)
    #     for i in range(N):
    #         _, traj = generate_agent_states(final_u[i], init_states[i], init_pos[i], model=Quadrocopter, dt=Tf/H*1.5)
    #         ax.scatter(traj[:,0], traj[:,1], traj[:,2], label=i)
    #         final_trajectories.append(traj)
    #     obs = plt.Circle((co[0], co[1]), ro, fill=True, alpha=0.2, color='red')
    #     ax.add_patch(obs)
    #     art3d.pathpatch_2d_to_3d(obs, z=co[2])
    #     goal = plt.Circle((cg[0], cg[1]), rg, fill=True, alpha=0.2, color='green')
    #     ax.add_patch(goal)
    #     art3d.pathpatch_2d_to_3d(goal, z=cg[2])
    #     plt.savefig('plots/quad/agent_final_trajectories_central_N{}.png'.format(N))
    #     plt.clf()

    #     valid_sol = obj.check_avoid_constraints(final_u)
    #     print('Central: Valid Solution? All Agents Avoid Obstacle: {}'.format(valid_sol))
    # else:
    #     print('Could Not solve Central')

    # SOLVE USING DISTRIBUTED OPTIMIZATION
    final_u, local_sols, fairness = obj.solve_distributed(init_u, steps=args.iter, dyn='quad')
    if len(fairness) == 0:
        print('Cannot Solve Distributed Problem')
        sys.exit()

    # METRICS FOR FINAL TRAJECTORY AFTER SOLVING DISTRIBUTED PROBLEM
    dist_sol_obj = obj.central_obj(final_u.flatten())
    print('Dist Final Obj {}'.format(dist_sol_obj))
    final_u = final_u.reshape(N, H, control_input_size)    
    print('Dist Final Total Energy Cost (Lower is better)')
    dist_sol_energy = obj.quad(final_u.flatten())
    print(dist_sol_energy)
    print('Dist Final Fairness (Close to 0 is better)')
    dist_sol_fairness = obj.fairness(final_u.flatten())
    print(dist_sol_fairness)
    print('Dist Final Obstacle Avoidance Cost (More Negative Is Better)')
    dist_sol_obstacle = obj.obstacle(final_u.flatten())
    print(dist_sol_obstacle)
    print('Dist Final Collision Avoidance Cost (More Negative Is Better)')
    dist_sol_collision = obj.avoid_constraint(final_u.flatten())
    print(dist_sol_collision)

    # PLOT FINAL TRAEJECTORIES FROM CONTROL INPUTS
    final_trajectories = []
    fig = plt.figure()
    ax = fig.add_subplot(projection='3d')
    times = np.linspace(0, Tf, H)
    for i in range(N):
        _, traj = generate_agent_states(final_u[i], init_states[i], init_pos[i], model=Quadrocopter, dt=Tf/H*1.5)
        # _, traj = generate_agent_states(final_u[i], init_states[i], init_pos[i], model=Quadrocopter, dt=1.0/H+EPS)
        ax.scatter(traj[:,0], traj[:,1], traj[:,2], label=i)
        final_trajectories.append(traj)
    obs = plt.Circle((co[0], co[1]), ro, fill=True, alpha=0.2, color='red')
    ax.add_patch(obs)
    art3d.pathpatch_2d_to_3d(obs, z=co[2])
    goal = plt.Circle((cg[0], cg[1]), rg, fill=True, alpha=0.2, color='green')
    ax.add_patch(goal)
    art3d.pathpatch_2d_to_3d(goal, z=cg[2])
    plt.savefig('plots/quad/agent_final_trajectories_dist_N{}.png'.format(N))
    # plt.show()
    plt.clf()

    valid_sol = obj.check_avoid_constraints(final_u)
    print('Distributed: Valid Solution? All Agents Avoid Obstacle: {}'.format(valid_sol))


    # Convergence Plot
    for i in range(N):
        plt.plot(local_sols[i], label='Agent {} Local Objective Value'.format(i))
    plt.legend()
    plt.savefig('plots/quad/local_objective_solution_convergence_N{}.png'.format(N))
    plt.clf()

    # Fairness Plot
    plt.plot(fairness)
    plt.savefig('plots/quad/distributed_fairness_over_time_N{}.png'.format(N))
    plt.clf()

    # Comparison Plots
    labels = ['J', 'Energy', 'Fairness', 'Collision']
    distributed_values = [dist_sol_obj, dist_sol_energy, dist_sol_fairness, dist_sol_obstacle+dist_sol_collision]
    central_values = [central_sol_obj, central_sol_energy, central_sol_fairness, central_sol_obstacle+central_sol_collision]
    init_values = [init_obj, init_energy, init_fairness, init_obstacle+init_collision]

    x = np.arange(len(labels))  # the label locations
    width = 0.3  # the width of the bars

    fig, ax = plt.subplots()
    rects1 = ax.bar(x - width, distributed_values, width, label='Distributed')
    rects2 = ax.bar(x, central_values, width, label='Central')
    rects3 = ax.bar(x + width, init_values, width, label='Initial')

    # ax.set_ylabel('Scores')
    ax.set_title('Objective Values')
    ax.set_xticks(x, labels)
    ax.legend()

    ax.bar_label(rects1, padding=3, labels=[f'{x:.1f}' for x in rects1.datavalues])
    ax.bar_label(rects2, padding=3, labels=[f'{x:.1f}' for x in rects2.datavalues])
    ax.bar_label(rects3, padding=3, labels=[f'{x:.1f}' for x in rects3.datavalues])

    fig.tight_layout()

    plt.savefig('plots/quad/objective_values_comparison_N{}.png'.format(N))
    plt.clf()

    # # Objective Comparison Plot
    # plt.hlines(dist_sol_obj, xmin=0, xmax=args.iter, linestyles='solid', label='Distributed Objective Value')
    # plt.hlines(central_sol_obj, xmin=0, xmax=args.iter, linestyles='dashed', label='Central Objective Value')
    # plt.hlines(init_obj, xmin=0, xmax=args.iter, linestyles='dotted', label='Initial Objective Value')
    # plt.legend()
    # plt.savefig('plots/quad/final_objective_value_comparison_N{}.png'.format(N))
    # plt.clf()

    # # Energy Comparison Plot
    # plt.hlines(dist_sol_energy, xmin=0, xmax=args.iter, linestyles='solid', label='Distributed Objective Value')
    # plt.hlines(central_sol_energy, xmin=0, xmax=args.iter, linestyles='dashed', label='Central Objective Value')
    # plt.hlines(init_energy, xmin=0, xmax=args.iter, linestyles='dotted', label='Initial Objective Value')
    # plt.legend()
    # plt.savefig('plots/quad/final_energy_value_comparison_N{}.png'.format(N))
    # plt.clf()

    # # Fairness Comparison Plot
    # plt.hlines(dist_sol_fairness, xmin=0, xmax=args.iter, linestyles='solid', label='Distributed Objective Value')
    # plt.hlines(central_sol_fairness, xmin=0, xmax=args.iter, linestyles='dashed', label='Central Objective Value')
    # plt.hlines(init_fairness, xmin=0, xmax=args.iter, linestyles='dotted', label='Initial Objective Value')
    # plt.legend()
    # plt.savefig('plots/quad/final_fairness_value_comparison_N{}.png'.format(N))
    # plt.clf()

    # # Obstacle Avoidance Comparison Plot
    # plt.hlines(dist_sol_obstacle, xmin=0, xmax=args.iter, linestyles='solid', label='Distributed Objective Value')
    # plt.hlines(central_sol_obstacle, xmin=0, xmax=args.iter, linestyles='dashed', label='Central Objective Value')
    # plt.hlines(init_obstacle, xmin=0, xmax=args.iter, linestyles='dotted', label='Initial Objective Value')
    # plt.legend()
    # plt.savefig('plots/quad/final_obstacle_value_comparison_N{}.png'.format(N))
    # plt.clf()

    # # Collision Avoidance Comparison Plot
    # plt.hlines(dist_sol_collision, xmin=0, xmax=args.iter, linestyles='solid', label='Distributed Objective Value')
    # plt.hlines(central_sol_collision, xmin=0, xmax=args.iter, linestyles='dashed', label='Central Objective Value')
    # plt.hlines(init_collision, xmin=0, xmax=args.iter, linestyles='dotted', label='Initial Objective Value')
    # plt.legend()
    # plt.savefig('plots/quad/final_collision_value_comparison_N{}.png'.format(N))
    # plt.clf()

